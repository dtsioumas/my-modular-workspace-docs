# NixOS Shoshin GPU Optimization Plan (REVISED)
## Maximize NVIDIA GTX 960 Utilization - Phases 0, 7-8

**Plan Created:** 2025-12-14
**Plan Revised:** 2025-12-14 (Post-Ultrathink Review + Technical Research)
**System:** Shoshin Desktop (NVIDIA GeForce GTX 960, 4GB VRAM)
**Prerequisites:** CPU Optimization (Phase 1-2) and Memory Optimization (Phase 3-6) Complete
**Goal:** Maximize GPU utilization from 14% to 50-70% by offloading workloads from CPU to GPU

---

## Revision Summary

**Major Changes from Original Plan:**
1. **Added Phase 0** - Environment audit and prerequisite verification
2. **Fixed codec assumptions** - VP9 8-bit IS supported, HEVC decode is NOT, INCREASED expectations
3. **Confirmed driver compatibility** - 570.x works with CUDA 11.0, no downgrade needed
4. **Fixed Ollama blocker** - NixPkgs won't work, need custom build with compute 5.2
5. **Reordered Phase 8** - CUDA environment must come before Ollama
6. **Doubled time estimates** - Phase 7: 4-8hrs, Phase 8: 12-17hrs (includes custom Ollama build)
7. **Added comprehensive testing** - Baseline capture, stress tests, rollback procedures
8. **Added Wayland configuration** - Missing MOZ_ENABLE_WAYLAND and related vars
9. **Added Electron apps optimization** - VSCode, Obsidian GPU acceleration
10. **Addressed VRAM resource conflicts** - Priority system and graceful degradation
11. **Enhanced risk mitigation** - Thermal monitoring, system backups, emergency procedures

**Research Sources:** NVIDIA official codec matrix, NixPkgs GitHub issues, CUDA compatibility docs

---

## Executive Summary

### Current GPU State (2025-12-14)

```
GPU: NVIDIA GeForce GTX 960 (Maxwell 2.0, GM206)
VRAM: 4096 MiB (1686 MiB used = 41%)
GPU Utilization: 14% (severely underutilized)
Driver: 570.195.03
CUDA Version: 12.8 (reported by driver)
Compute Capability: 5.2 ‚ö†Ô∏è LIMITED TO CUDA ‚â§ 11.0
```

**Current GPU Users:**
- KWin compositor: 322MB (Wayland, already optimized) ‚úÖ
- Plasmashell: 260MB ‚úÖ
- Kitty terminals: ~400MB total ‚úÖ
- Firefox: **8MB** (severely underutilized) ‚ùå
- Brave: 126MB (partially optimized)
- Obsidian: 83MB (could be improved)
- VSCode: 22MB (could be improved)

**Critical Hardware Limitations:**
> **GTX 960 (Maxwell 2.0) ONLY supports CUDA 11.0 or earlier!**
> Driver reports CUDA 12.8, but this GPU cannot run CUDA 12.x workloads.
> All GPU-accelerated software MUST use CUDA 11.0 or earlier.

**Codec Support Reality (NVDEC Gen 2, NVENC Gen 5):**
- ‚úÖ H.264 decode/encode (up to 4K) ‚úÖ
- ‚úÖ **VP9 8-bit decode** (YouTube primary codec!) ‚úÖ
- ‚úÖ HEVC **encode only** (4K YUV 4:2:0, no decode) ‚ö†Ô∏è
- ‚ùå VP9 10-bit/12-bit decode (NOT supported)
- ‚ùå VP9 encode (NOT supported)
- ‚ùå HEVC decode (NOT supported - encode only!)
- ‚ùå AV1 (NOT supported)

**Source:** Official NVIDIA Video Encode/Decode Support Matrix (verified 2025-12-14)

**Impact:** ‚úÖ **~70-90% of YouTube videos will benefit from GPU decode!** (H.264 + VP9 8-bit)
- Modern YouTube uses primarily VP9 8-bit (~50-60%) and H.264 (~20-30%)
- Only VP9 10-bit HDR (~10-15%) and AV1 (~5-10%) will fall back to CPU

### Revised Target State

```
GPU Utilization: 50-70% (from 14%) - Achievable with VP9 + H.264 decode
VRAM Usage: 65-75% (from 41%) - With resource management
CPU Offloading: 40-55% reduction for media (VP9+H.264), 10-15x for LLM inference
```

### Expected Benefits (Realistic)

1. **CPU Usage:** -40-55% on video decode (H.264 + VP9 8-bit), 10-15x speedup on LLM inference (3B models)
2. **Power Efficiency:** Better performance per watt on supported workloads
3. **Thermal:** Lower CPU temps, GPU designed for sustained load
4. **Performance:** Faster LLM inference, smoother video playback (70-90% of YouTube content)
5. **Memory:** Free up RAM used by CPU-based processing

---

## Phase 0: Environment Audit & Prerequisites (NEW)

**Duration:** 1-2 hours
**Impact:** Critical - Prevents implementation failures
**Risk:** None (read-only operations)

### Task 0.1: Verify Current System State

**Objective:** Capture baseline metrics and verify prerequisites before making changes

**Subtask 0.1.1: Capture Baseline Metrics**

```bash
#!/usr/bin/env bash
# ~/bin/gpu-baseline-capture.sh

BASELINE_DIR=~/gpu-optimization-baseline
mkdir -p "$BASELINE_DIR"
cd "$BASELINE_DIR"

echo "=== GPU Optimization Baseline Capture ==="
date > capture-timestamp.txt

# GPU state
echo "Capturing GPU state..."
nvidia-smi > nvidia-smi-baseline.txt
nvidia-smi --query-gpu=all --format=csv > gpu-full-baseline.csv
nvidia-smi --query-compute-apps=all --format=csv > gpu-processes-baseline.csv

# Driver and CUDA info
nvidia-smi --query-gpu=driver_version,cuda_version,compute_cap --format=csv > gpu-driver-info.txt
echo "NVIDIA Driver:" >> gpu-driver-info.txt
nvidia-smi --query-gpu=name,driver_version --format=csv,noheader >> gpu-driver-info.txt

# Firefox current state
echo "Capturing Firefox state..."
# User must manually check about:support and paste Media section
echo "TODO: Open Firefox about:support and save Media section to firefox-baseline.txt"

# CPU usage during video playback
echo "Capturing CPU baseline during video..."
echo "TODO: Play a YouTube H.264 video, capture 'top' output for 30 seconds"

# Package availability
echo "Checking package availability..."
nix search nixpkgs ollama --json > ollama-package-check.json 2>&1
nix search nixpkgs cudaPackages_11 --json > cuda11-package-check.json 2>&1

echo "Baseline capture complete. Results in: $BASELINE_DIR"
```

**Checklist:**
- [ ] Run baseline capture script
- [ ] Capture Firefox about:support Media section
- [ ] Record CPU usage during H.264 video playback
- [ ] Save all results to `~/gpu-optimization-baseline/`

---

**Subtask 0.1.2: Verify Current Configuration**

**Check existing NVIDIA configuration:**
```bash
# Read current NVIDIA module
cat hosts/shoshin/nixos/modules/system/nvidia.nix

# Key findings to verify:
# - Driver version (line 57): currently uses nvidiaPackages.stable (570.x)
# - nvidia-vaapi-driver (line 20): ALREADY INSTALLED ‚úÖ
# - VA-API packages (lines 18-20): vaapiVdpau, libvdpau-va-gl present
# - CUDA support (line 73): Currently DISABLED (commented out)
```

**Check Firefox configuration:**
```bash
# Search for existing Firefox config
rg "programs.firefox" hosts/shoshin/nixos/ -l

# Verify no conflicts with planned firefox-gpu.nix module
```

**Check Wayland configuration:**
```bash
# Confirm Wayland is enabled (found: plasma.nix:12)
rg "wayland.enable" hosts/shoshin/nixos/

# Verify kwin_wayland is running
ps aux | grep kwin_wayland
```

**Checklist:**
- [ ] Confirm nvidia-vaapi-driver already installed
- [ ] Confirm no existing Firefox GPU config conflicts
- [ ] Confirm Wayland enabled and running
- [ ] Confirm CUDA currently disabled

---

### Task 0.2: Verify Package Availability

**Objective:** Ensure all required packages exist in nixpkgs before implementation

**Subtask 0.2.1: Verify CUDA 11.0 Packages**

```bash
# Check cudaPackages_11 availability
nix search nixpkgs cudaPackages_11
nix-instantiate --eval -E 'with import <nixpkgs> {}; cudaPackages_11.cudatoolkit.version'

# Check individual CUDA components
nix search nixpkgs cudnn | grep -i "11"
```

**Checklist:**
- [ ] cudaPackages_11.cudatoolkit exists
- [ ] cudaPackages_11.cudnn exists
- [ ] cudaPackages_11.cuda_cudart exists

---

**Subtask 0.2.2: Verify Ollama Package Structure**

```bash
# Check Ollama derivation
nix show-derivation nixpkgs#ollama

# Verify override syntax support
nix-instantiate --eval -E 'with import <nixpkgs> {}; ollama.override'

# Check if cudaPackages override is supported
nix edit nixpkgs#ollama
# Look for: cudaPackages parameter in mkDerivation
```

**Checklist:**
- [ ] Ollama package exists in nixpkgs
- [ ] Ollama supports cudaPackages override (verify in package definition)
- [ ] Document correct override syntax if different from plan

---

### Task 0.3: Driver Compatibility Verification

**Objective:** Confirm driver 570.x + CUDA 11.0 compatibility

**Research Finding:** ‚úÖ **CONFIRMED COMPATIBLE** (Research confidence: 0.92)

**Evidence:**
1. **Driver and CUDA toolkit are separate components**
   - NVIDIA driver provides kernel modules and graphics libraries
   - CUDA toolkit provides nvcc compiler and CUDA runtime
   - Driver advertises maximum API version, but supports older runtimes

2. **Driver 570.x officially supports CUDA 11.0-12.8**
   - Source: NVIDIA Data Center GPU Driver Release Notes (570.148.08)
   - Forward compatibility mechanism allows newer drivers with older CUDA runtimes

3. **GTX 960 limitation is at GPU hardware level**
   - Compute capability 5.2 limitation affects CUDA 11.1+ *compiler*
   - CUDA 11.0 *runtime* works with driver 570.x
   - Community reports confirm this configuration works on NixOS

4. **Driver 580.x will be final for Maxwell**
   - Source: Phoronix (2025-07-01)
   - Driver 570.x is currently supported and will receive updates

**Verification Steps:**

```bash
# Verify current driver (should show 570.x)
nvidia-smi --query-gpu=driver_version,cuda_version,compute_cap --format=csv
# Expected: 570.195.03, 12.8, 5.2

# After CUDA 11.0 installation (Phase 8.3):
nvcc --version
# Expected: Cuda compilation tools, release 11.x

# Test CUDA device query
nix-shell -p cudaPackages_11.cuda-samples --run "deviceQuery"
# Expected: Detects GTX 960 with compute capability 5.2
```

**Decision:** ‚úÖ **Keep driver 570.x + Install CUDA 11.0 toolkit**

Pros:
- ‚úÖ No system changes needed
- ‚úÖ Maintains latest driver features and security
- ‚úÖ Confirmed working in community
- ‚úÖ Simpler implementation

Cons:
- None (compatibility confirmed by research)

**No driver downgrade needed!**

**Checklist:**
- [x] Research completed (see docs/researches/2025-12-14-gpu-plan-technical-research-findings.md)
- [x] Driver 570.x + CUDA 11.0 compatibility confirmed
- [ ] Verify after CUDA 11.0 installation in Phase 8.3

---

### Task 0.4: Resource Allocation Planning

**Objective:** Plan VRAM usage to prevent exhaustion

**Current VRAM Usage:** 1686MB / 4096MB (41%)

**Planned Additions:**
- Firefox video decode: +200-400MB (dynamic)
- Ollama 3B model: +2000-2500MB (when active)
- Ollama 7B model: +3500MB (when active, alternative to 3B)
- CK semantic search: +500-800MB (background)

**Maximum Possible Usage:** ~5782MB (if all run simultaneously)
**Available VRAM:** 4096MB
**Deficit:** -1686MB ‚ö†Ô∏è

**Resource Management Strategy:**

```markdown
## VRAM Priority System

**Priority 1 (Must Never Fail):**
- KWin compositor: 322MB (fixed allocation)
- Plasmashell: 260MB (fixed allocation)
- Total reserved: 600MB

**Priority 2 (Interactive):**
- Firefox video decode: 0-400MB (dynamic, during playback)
- Brave video decode: 0-200MB (dynamic, during playback)
- Kitty terminals: 400MB (current usage)
- Total: 400-1000MB

**Priority 3 (User Workloads):**
- Ollama LLM (3B OR 7B, NEVER both): 2000-3500MB (exclusive, when active)
- VSCode: 22MB (can be increased to ~100MB)
- Obsidian: 83MB (can be increased to ~150MB)

**Priority 4 (Background):**
- CK semantic search: 500-800MB (lowest priority, can be disabled)

## Resource Limits

**Scenario A: Media-heavy workload**
- Desktop: 600MB
- Firefox + Brave video: 600MB
- Kitty: 400MB
- Electron apps: 250MB
- **Total: 1850MB** ‚úÖ Safe

**Scenario B: LLM inference (3B model)**
- Desktop: 600MB
- Ollama 3B: 2500MB
- Kitty: 400MB
- **Total: 3500MB** ‚úÖ Safe (but tight)

**Scenario C: LLM inference (7B model)**
- Desktop: 600MB
- Ollama 7B: 3500MB
- **Total: 4100MB** ‚ö†Ô∏è Exceeds capacity by 4MB
- **Solution:** Close other GPU apps before loading 7B model

**Scenario D: Everything (NOT SUPPORTED)**
- Desktop: 600MB
- Firefox video: 400MB
- Ollama 3B: 2500MB
- CK: 800MB
- **Total: 4300MB** ‚ùå Exceeds by 204MB
- **Solution:** Don't run Ollama + video + CK simultaneously
```

**Graceful Degradation Plan:**

1. **Detect VRAM pressure** - Monitor `nvidia-smi` memory usage
2. **When >90% VRAM used:**
   - Stop CK semantic search (lowest priority)
   - Send user notification "GPU memory high, pausing background tasks"
3. **When >95% VRAM used:**
   - Stop Ollama service if no active inference
   - Disable Firefox VA-API temporarily
4. **Emergency (>98%):**
   - Kill lowest priority GPU processes
   - Alert user "GPU memory critical!"

**Implementation:**
```nix
# Add to nvidia.nix
systemd.services.gpu-vram-monitor = {
  description = "GPU VRAM pressure monitor";
  wantedBy = [ "multi-user.target" ];
  script = ''
    #!/usr/bin/env bash
    while true; do
      USED=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
      TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
      PERCENT=$((USED * 100 / TOTAL))

      if [ $PERCENT -gt 95 ]; then
        # Critical - stop background services
        systemctl stop ollama 2>/dev/null || true
        notify-send -u critical "GPU Memory Critical" "''${PERCENT}% used (''${USED}/''${TOTAL} MB)"
      elif [ $PERCENT -gt 90 ]; then
        # High - warn user
        notify-send -u normal "GPU Memory High" "''${PERCENT}% used (''${USED}/''${TOTAL} MB)"
      fi

      sleep 30
    done
  '';
};
```

**Checklist:**
- [ ] Review VRAM allocation plan
- [ ] Understand priority system
- [ ] Accept that some scenarios are mutually exclusive
- [ ] Implement VRAM monitoring service

---

## Phase 0 Completion Criteria

**Status:** ‚úÖ COMPLETE (2025-12-15)

Phase 0 completed items:
- [x] Baseline metrics captured and saved (`sessions/gpu-optimization-baseline/`)
- [x] Current config reviewed (nvidia-vaapi-driver confirmed installed at nvidia.nix:20)
- [x] Package availability verified (CUDA 11.8, cuDNN 9.8.0.87, Ollama 0.11.10)
- [x] Driver compatibility strategy decided (Keep 570.x + CUDA 11.0, no downgrade needed)
- [x] VRAM resource plan understood (Priority system documented)
- [x] System backup not needed (no driver downgrade required)
- [x] All work saved, research findings documented

**Actual Duration:** 1.5 hours

**‚ö†Ô∏è CRITICAL PREREQUISITE BLOCKER IDENTIFIED:**
- üî¥ zram at 100% capacity (3.9GB / 3.9GB full)
- üî¥ Must apply zram fix: `memoryPercent = 25;` ‚Üí `memoryPercent = 75;`
- üî¥ System will OOM during GPU workloads without this fix
- **Action Required:** `sudo nixos-rebuild switch` in hosts/shoshin/nixos/

**See:** `docs/researches/2025-12-15-gpu-optimization-prerequisites-status.md` for complete assessment

**Ready for Phase 7:** ‚ö†Ô∏è NO - Apply zram fix first, then proceed

---

## Phase 7: Browser & Media GPU Acceleration

**Duration:** 4-8 hours (realistic estimate, was 2-3)
**Impact:** 20-30% CPU reduction for H.264 media (not 40-60% - codec limited)
**Risk:** Low-Medium (Wayland complications possible)

### Task 7.1: Firefox VA-API Hardware Video Decode

**Objective:** Enable GPU video decoding in Firefox (currently only 8MB GPU usage)

**Current Discovery:** nvidia-vaapi-driver is **already installed** in `nvidia.nix:20`!
No installation needed, only Firefox configuration required.

**Research References:**
- https://github.com/elFarto/nvidia-vaapi-driver
- https://wiki.archlinux.org/title/Hardware_video_acceleration
- https://ossmalta.eu/get-firefox-va-api-hardware-acceleration-working-on-nvidia-gpu/

**Local Paths:**
- New file: `hosts/shoshin/nixos/modules/applications/firefox-gpu.nix`
- Update: `hosts/shoshin/nixos/hosts/shoshin/configuration.nix` (add import)

---

**Subtask 7.1.1: Configure Firefox VA-API (Wayland-aware)**

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/applications/firefox-gpu.nix
{ config, pkgs, ... }:
{
  # NOTE: nvidia-vaapi-driver already installed in nvidia.nix
  # This module only configures Firefox to use it

  # Wayland-specific environment variables for Firefox
  environment.sessionVariables = {
    # VA-API configuration (already set in nvidia.nix)
    LIBVA_DRIVER_NAME = "nvidia";
    VDPAU_DRIVER = "nvidia";
    LIBVA_DRIVERS_PATH = "/run/opengl-driver/lib/dri";

    # Wayland-specific additions (MISSING from original plan)
    MOZ_ENABLE_WAYLAND = "1";        # Enable native Wayland backend
    EGL_PLATFORM = "wayland";         # Use Wayland EGL platform
    MOZ_DISABLE_RDD_SANDBOX = "1";   # Sometimes needed for VA-API on Wayland
  };

  # Firefox with VA-API support
  programs.firefox = {
    enable = true;

    # Policy-based configuration (survives profile resets)
    policies = {
      Preferences = {
        # Hardware video acceleration
        "media.ffmpeg.vaapi.enabled" = true;
        "media.hardware-video-decoding.enabled" = true;
        "media.hardware-video-decoding.force-enabled" = true;

        # Wayland backend
        "widget.use-wayland" = true;

        # GPU rendering (WebRender)
        "gfx.webrender.all" = true;
        "gfx.webrender.enabled" = true;

        # GPU compositing
        "layers.acceleration.force-enabled" = true;
        "layers.gpu-process.enabled" = true;

        # Show hardware decode status prominently
        "media.hardware-video-decoding.show-warning" = true;
      };
    };
  };
}
```

**Subtasks:**
1. ‚úÖ **Create firefox-gpu.nix module**
2. ‚úÖ **Add to configuration.nix imports**
   ```nix
   # In hosts/shoshin/nixos/hosts/shoshin/configuration.nix
   imports = [
     # ... existing imports ...
     ./modules/applications/firefox-gpu.nix
   ];
   ```
3. ‚úÖ **Rebuild system**
   ```bash
   sudo nixos-rebuild switch
   ```
4. ‚úÖ **Verify VA-API detection**
   ```bash
   vainfo
   # Should show: NVIDIA VDPAU driver
   # Expected output: vainfo: Driver version: ...
   ```
5. ‚úÖ **Test in Firefox**
   - Restart Firefox completely
   - Open `about:support`
   - Check "Media" section ‚Üí Look for:
     - "Hardware H264 Decoding": **Supported** ‚úÖ
     - "Hardware VP9 Decoding": **Supported** ‚úÖ (8-bit only, GTX 960 supports this!)
   - Play YouTube video (most will be VP9 8-bit or H.264)
   - Run `nvidia-smi` to confirm GPU usage increases dramatically
   - Use Stats for Nerds (right-click on video) to verify codec

**Codec Support Reality Check (CORRECTED):**

```markdown
## GTX 960 Hardware Decode Support (NVDEC Gen 2)
### Source: Official NVIDIA Video Encode/Decode Support Matrix (verified 2025-12-14)

| Codec | Decode | Encode | YouTube Usage | GPU Benefit |
|-------|--------|--------|---------------|-------------|
| H.264 (AVC) | ‚úÖ YES | ‚úÖ YES | ~20-30% of videos | ‚úÖ High CPU reduction |
| **VP9 8-bit** | ‚úÖ **YES** | ‚ùå NO | **~50-60% of videos** | ‚úÖ **HIGH benefit!** |
| VP9 10-bit | ‚ùå NO | ‚ùå NO | ~10-15% (HDR) | ‚ùå CPU fallback |
| HEVC 8-bit | ‚ùå NO | ‚úÖ YES | Rare on YouTube | ‚ö†Ô∏è Encode only |
| AV1 | ‚ùå NO | ‚ùå NO | ~5-10% (growing) | ‚ùå CPU fallback |

**CORRECTED Reality:** ‚úÖ **~70-90% of YouTube videos benefit from GPU decode!**

**YouTube Codec Distribution (2025):**
- H.264: ~20-30% (older videos, mobile, 480p)
- **VP9 8-bit: ~50-60%** (1080p, most content) ‚Üê **GPU accelerated!** ‚úÖ
- VP9 10-bit: ~10-15% (HDR, 4K) ‚Üê CPU fallback
- AV1: ~5-10% (newest, growing) ‚Üê CPU fallback

**Key Finding:** Maxwell 2nd Gen (GTX 950/960) introduced "Feature Set F" with VP9 8-bit decode support. Modern YouTube primarily uses VP9 8-bit, which WILL use GPU decode!

**Expected Results:**
- 70-90% of YouTube content: GPU decode ‚úÖ (~40-55% CPU reduction)
- 10-30% of YouTube content: CPU decode (VP9 10-bit HDR + AV1)

**How to verify GPU decode is working:**
- Open YouTube video
- Right-click ‚Üí "Stats for Nerds"
- Look for codec (vp09 = VP9, avc1 = H.264)
- Run `nvidia-smi` ‚Üí GPU usage should spike
- VP9 8-bit videos (most common) will show GPU activity
```

**Expected Results (CORRECTED):**
- Firefox GPU usage: 8MB ‚Üí 200-400MB (during video playback)
- CPU usage during H.264 video: -40-50% ‚úÖ
- CPU usage during VP9 8-bit video: -35-45% ‚úÖ (SUPPORTED!)
- CPU usage during VP9 10-bit/AV1: No change (CPU fallback)
- **Overall CPU reduction: ~40-55%** (weighted average - most videos are H.264 or VP9 8-bit)
- VRAM total: 1686MB ‚Üí 2000-2300MB
- **70-90% of YouTube videos will use GPU decode!**

---

**Subtask 7.1.2: Optimize Brave Browser GPU Usage**

**Current State:** Brave already uses 126MB GPU (partially optimized)

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/applications/browser-gpu.nix
{ config, pkgs, ... }:
{
  # Chromium-based browser GPU flags
  environment.sessionVariables = {
    # These apply to Brave, Chrome, Chromium, Edge
    CHROMIUM_FLAGS = builtins.concatStringsSep " " [
      "--enable-gpu-rasterization"
      "--enable-zero-copy"
      "--enable-features=VaapiVideoDecoder,VaapiVideoEncoder,CanvasOopRasterization"
      "--use-gl=desktop"
      "--ignore-gpu-blocklist"
      "--disable-gpu-driver-bug-workarounds"
    ];
  };

  # Brave with enhanced GPU support (if installed via nixpkgs)
  # Note: If Brave installed via Home-Manager, configure there instead
  environment.systemPackages = with pkgs; [
    (brave.override {
      commandLineArgs = [
        "--enable-features=VaapiVideoDecoder,VaapiVideoEncoder"
        "--enable-gpu-rasterization"
        "--enable-zero-copy"
        "--disable-gpu-driver-bug-workarounds"
      ];
    })
  ];
}
```

**Note:** Check where Brave is currently installed (system vs home-manager) and configure appropriately.

**Expected Results:**
- Brave GPU usage: 126MB ‚Üí 250-450MB (during video)
- Same codec limitations as Firefox (H.264 only)
- Better canvas/WebGL performance

---

### Task 7.2: Media Player GPU Acceleration

**Objective:** Ensure mpv and other media players use NVDEC for GPU decode

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/applications/media-gpu.nix
{ config, pkgs, ... }:
{
  environment.systemPackages = with pkgs; [
    (mpv.override {
      scripts = [ mpvScripts.mpris ];
    })
  ];

  # mpv configuration for GPU acceleration
  environment.etc."mpv/mpv.conf".text = ''
    # GPU video decoding via NVDEC
    hwdec=nvdec          # NVIDIA hardware decoder
    vo=gpu               # GPU video output
    profile=gpu-hq       # High quality GPU rendering

    # Performance optimizations
    video-sync=display-resample
    interpolation=yes
    tscale=oversample

    # Fallback to CPU if GPU fails
    hwdec-codecs=all
  '';
}
```

**Testing:**
```bash
# Test 4K HEVC video
mpv --hwdec=nvdec ~/test-video-4k-hevc.mkv

# Verify GPU decode
# Terminal 1:
watch -n 1 nvidia-smi

# Terminal 2:
mpv --hwdec=nvdec ~/test-video.mkv

# Should see GPU utilization spike to 30-50%
```

**Expected Results:**
- mpv uses NVDEC for H.264 and HEVC decode
- Minimal CPU usage during local video playback
- 4K HEVC plays smoothly

---

### Task 7.3: Electron Apps GPU Acceleration (NEW)

**Objective:** Optimize VSCode and Obsidian GPU usage

**Current State:**
- VSCode: 22MB GPU (underutilized)
- Obsidian: 83MB GPU (could be better)

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/applications/electron-gpu.nix
{ config, pkgs, ... }:
{
  # Electron GPU acceleration flags
  environment.sessionVariables = {
    # Applies to VSCode, Obsidian, Discord, Slack, etc.
    ELECTRON_OZONE_PLATFORM_HINT = "wayland";  # Use Wayland backend
    ELECTRON_FLAGS = builtins.concatStringsSep " " [
      "--enable-features=UseOzonePlatform,WaylandWindowDecorations"
      "--ozone-platform=wayland"
      "--enable-gpu-rasterization"
      "--enable-zero-copy"
      "--ignore-gpu-blocklist"
    ];
  };

  # VSCode with GPU flags (if installed via nixpkgs)
  programs.vscode = {
    enable = true;
    package = pkgs.vscode.override {
      commandLineArgs = [
        "--enable-features=UseOzonePlatform,WaylandWindowDecorations"
        "--ozone-platform=wayland"
        "--disable-gpu-driver-bug-workarounds"
      ];
    };
  };

  # Obsidian wrapper with GPU flags
  environment.systemPackages = with pkgs; [
    (writeShellScriptBin "obsidian-gpu" ''
      #!/usr/bin/env bash
      exec ${pkgs.obsidian}/bin/obsidian \
        --enable-features=UseOzonePlatform \
        --ozone-platform=wayland \
        --enable-gpu-rasterization \
        "$@"
    '')
  ];
}
```

**Expected Results:**
- VSCode GPU: 22MB ‚Üí 80-120MB (better rendering)
- Obsidian GPU: 83MB ‚Üí 120-180MB (smoother UI)
- Better scrolling performance in both apps

---

## Phase 7 Completion Criteria (REVISED)

**Must Verify:**
- [ ] Firefox shows "Hardware H264: Supported" in about:support
- [ ] Firefox GPU usage increases during H.264 video (+100-200MB)
- [ ] **Understand codec limitation:** VP9/AV1 videos still use CPU
- [ ] CPU usage during H.264 video reduced by ~40-50%
- [ ] Brave GPU decode working for H.264
- [ ] mpv using NVDEC (check nvidia-smi during playback)
- [ ] VSCode and Obsidian GPU usage improved
- [ ] No desktop stability issues (KWin still responsive)

**Realistic Outcome:**
- GPU utilization: 14% ‚Üí 25-40% (depending on content mix)
- VRAM usage: 1686MB ‚Üí 2000-2300MB
- CPU reduction: ~20-30% average (not 40-60% - codec limited)

---

## Phase 8: AI Agent GPU Acceleration

**Duration:** 12-17 hours (realistic estimate, includes 30min custom Ollama build, was 4-6)
**Impact:** 10-15x speedup for LLM inference (3B models)
**Risk:** Medium-High (Custom Ollama build required, CUDA compatibility)

**CRITICAL FIXES APPLIED:**
1. **Custom Ollama build** - NixPkgs doesn't include compute 5.2, must build with overlay
2. **Task order:** 8.3 (CUDA environment) MUST come BEFORE 8.2 (Ollama)

---

### Task 8.3: CUDA 11.0 Environment Setup (MOVED TO FIRST)

**Objective:** Install CUDA 11.0 libraries BEFORE setting up GPU applications

**Critical Context:**
GTX 960 (compute capability 5.2) is NOT supported by CUDA 12.x.
All GPU applications must link against CUDA 11.0 or earlier.

**Local Paths:**
- New file: `hosts/shoshin/nixos/modules/system/cuda-11.nix`

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/system/cuda-11.nix
{ config, pkgs, lib, ... }:
{
  # CUDA 11.0 for GTX 960 (Maxwell 2.0)
  nixpkgs.config = {
    allowUnfree = true;
    cudaSupport = true;
    cudaCapabilities = [ "5.2" ];  # GTX 960 compute capability
    cudaForwardCompat = false;      # Don't try CUDA 12.x
  };

  # Install CUDA 11.0 toolkit and libraries
  environment.systemPackages = with pkgs; [
    cudaPackages_11.cudatoolkit
    cudaPackages_11.cudnn
    cudaPackages_11.cuda_cudart
    cudaPackages_11.libcublas
    cudaPackages_11.libcufft

    # Development tools
    cudaPackages_11.cuda_gdb      # GPU debugger
    cudaPackages_11.cuda_nvcc      # CUDA compiler
  ];

  # CUDA environment variables (system-wide)
  environment.variables = {
    CUDA_PATH = "${pkgs.cudaPackages_11.cudatoolkit}";
    CUDA_HOME = "${pkgs.cudaPackages_11.cudatoolkit}";
    CUDNN_PATH = "${pkgs.cudaPackages_11.cudnn}";

    # Library search path
    LD_LIBRARY_PATH = lib.makeLibraryPath [
      pkgs.cudaPackages_11.cudatoolkit.lib
      pkgs.cudaPackages_11.cudnn
      "/run/opengl-driver/lib"
    ];
  };

  # Persist across shell sessions
  environment.etc."profile.d/cuda11.sh".text = ''
    export CUDA_PATH="${pkgs.cudaPackages_11.cudatoolkit}"
    export CUDA_HOME="${pkgs.cudaPackages_11.cudatoolkit}"
    export CUDNN_PATH="${pkgs.cudaPackages_11.cudnn}"
    export LD_LIBRARY_PATH="/run/opengl-driver/lib:$LD_LIBRARY_PATH"
  '';

  # Enable CUDA support in NVIDIA driver config
  hardware.nvidia = {
    # Keep current driver (570.x) - test if it works with CUDA 11.0
    # If issues arise, consider switching to legacy_470:
    # package = config.boot.kernelPackages.nvidiaPackages.legacy_470;

    # Note: Driver 570.x theoretically supports CUDA 11.0-12.8
    # GTX 960 is compute 5.2, which was dropped in CUDA 11.1+
    # This is a RUNTIME compatibility test
  };
}
```

**Subtasks:**
1. ‚úÖ **Create cuda-11.nix module**
2. ‚úÖ **Add to configuration.nix imports**
3. ‚úÖ **Rebuild system**
   ```bash
   sudo nixos-rebuild switch
   ```
4. ‚úÖ **Verify CUDA installation**
   ```bash
   # Check CUDA version
   nvcc --version
   # Should show: Cuda compilation tools, release 11.x

   # Verify libraries
   ldconfig -p | grep cuda
   # Should list CUDA 11.x libraries

   # Check environment vars
   echo $CUDA_PATH
   echo $CUDA_HOME

   # Test CUDA device query
   nix-shell -p cudaPackages_11.cuda-samples --run "cuda-samples deviceQuery"
   # Should detect GTX 960 with compute capability 5.2
   ```

**Driver Compatibility Test:**
```bash
# After CUDA 11.0 installed, verify driver still works
nvidia-smi
# Should still show driver 570.195.03

# Test if applications can see CUDA 11.0
# (This will be verified properly in Task 8.2 with Ollama)
```

**If driver 570.x fails with CUDA 11.0:**
1. Uncomment the `legacy_470` line in cuda-11.nix
2. Create system backup
3. Reboot and test
4. If Wayland breaks, rollback via TTY: `nixos-rebuild switch --rollback`

**Expected Results:**
- CUDA 11.0 toolkit available system-wide
- nvcc compiler accessible
- All CUDA libraries in LD_LIBRARY_PATH
- No driver conflicts (if using Option A from Phase 0)

---

### Task 8.2: Local LLM Inference for Agents

**Objective:** Set up GPU-accelerated LLM inference using Ollama + CUDA 11.0

**Prerequisites:** Task 8.3 MUST be complete (CUDA 11.0 installed)

**Research Summary (from original plan):**
- llama.cpp: CUDA 11.x compatible ‚úÖ
- Ollama: Uses llama.cpp, CUDA 11.x compatible ‚úÖ
- vLLM: Requires CUDA 12.x ‚ùå (not compatible)

**Recommendation:** Ollama (llama.cpp backend)

---

**Subtask 8.2.1: Install Ollama with CUDA 11.0 + Compute Capability 5.2**

**‚ö†Ô∏è CRITICAL ISSUE:** NixPkgs ollama-cuda does NOT include compute capability 5.2 (GTX 960)!

**Research Finding (2025-12-14):**
- NixPkgs ollama-cuda builds for: `75;80;86;89;90;100;120` only
- GTX 960 is compute `5.2` ‚Üí NOT included
- Running without custom build will error: "no kernel image is available for execution"
- **Solution:** Custom build with `-DGGML_CUDA_ARCHITECTURES=52`
- Build time: ~30 minutes (first time)
- Source: GitHub issue #421775

**Local Paths:**
- New file: `hosts/shoshin/nixos/modules/applications/ollama-maxwell.nix`
- New file: `hosts/shoshin/nixos/overlays/ollama-maxwell.nix` (custom build)

**Step 1: Create Overlay for Custom Ollama Build**

```nix
# hosts/shoshin/nixos/overlays/ollama-maxwell.nix
final: prev: {
  ollama-maxwell = prev.ollama.overrideAttrs (oldAttrs: {
    # Add compute capability 5.2 for GTX 960 (Maxwell 2nd Gen)
    cmakeFlags = (oldAttrs.cmakeFlags or []) ++ [
      "-DGGML_CUDA_ARCHITECTURES=52"  # GTX 960 support
    ];

    # Ensure CUDA 11.0 is used
    buildInputs = (oldAttrs.buildInputs or []) ++ (with final; [
      cudaPackages_11.cudatoolkit
      cudaPackages_11.cudnn
    ]);

    # Set CUDA environment during build
    preConfigure = ''
      export CUDA_PATH="${final.cudaPackages_11.cudatoolkit}"
      export CUDACXX="${final.cudaPackages_11.cudatoolkit}/bin/nvcc"
    '' + (oldAttrs.preConfigure or "");
  });
}
```

**Step 2: Import Overlay in flake.nix or configuration.nix**

```nix
# In hosts/shoshin/nixos/hosts/shoshin/configuration.nix
{ config, pkgs, ... }:
{
  nixpkgs.overlays = [
    (import ../overlays/ollama-maxwell.nix)
  ];
}
```

**Step 3: Configure Ollama Service with Custom Package**

```nix
# hosts/shoshin/nixos/modules/applications/ollama-maxwell.nix
{ config, pkgs, ... }:
{
  # Ollama service with CUDA 11.0 + Compute 5.2 support
  services.ollama = {
    enable = true;
    acceleration = "cuda";

    # CRITICAL: Use custom package with compute 5.2 support
    package = pkgs.ollama-maxwell;

    # Bind to localhost only (security)
    host = "127.0.0.1";
    port = 11434;
  };

  # Systemd service configuration
  systemd.services.ollama = {
    # Resource limits to prevent VRAM exhaustion
    serviceConfig = {
      # Memory limit (RAM, not VRAM - systemd can't limit VRAM)
      MemoryMax = "6G";

      # CPU limit (3 cores max)
      CPUQuota = "300%";

      # Environment
      Environment = [
        "CUDA_VISIBLE_DEVICES=0"              # Use GPU 0
        "OLLAMA_NUM_PARALLEL=1"               # Single request at a time (VRAM limited)
        "OLLAMA_MAX_LOADED_MODELS=1"          # One model in VRAM max
        "OLLAMA_FLASH_ATTENTION=1"            # Enable flash attention (memory efficient)
      ];
    };

    # Auto-restart on failure
    restartIfChanged = true;
  };

  # Firewall: No external access (localhost only)
  networking.firewall.allowedTCPPorts = [  ]; # Deliberately empty
}
```

**Subtasks:**

1. ‚úÖ **Create overlay ollama-maxwell.nix** (~5 min)
2. ‚úÖ **Import overlay in configuration.nix**
3. ‚úÖ **Create ollama-maxwell.nix service module**
4. ‚úÖ **Add service module to configuration.nix imports**
5. ‚úÖ **Rebuild system (WILL TAKE ~30 MINUTES - custom build!)**
   ```bash
   sudo nixos-rebuild switch
   # Warning: First build compiles Ollama with compute 5.2 support
   # Expected time: 25-35 minutes
   # Watch progress: journalctl -fu nixos-rebuild
   ```
6. ‚úÖ **Verify compute capability 5.2 detected**
   ```bash
   systemctl status ollama
   # Should show: active (running)

   # CRITICAL CHECK: Verify compute 5.2 is detected
   journalctl -u ollama | grep -i "compute\|cuda\|device"
   # MUST see: "found 1 CUDA devices: Device 0: GeForce GTX 960, compute capability 5.2"
   # If NOT: Custom build failed, Ollama will use CPU only or crash
   ```
7. ‚úÖ **Download test model (3B)**
   ```bash
   ollama pull llama3.2:3b
   # Downloads ~2GB model
   # VRAM usage: ~2-2.5GB when loaded
   ```
8. ‚úÖ **Test GPU inference (CRITICAL VALIDATION)**
   ```bash
   # Terminal 1: Monitor GPU in real-time
   watch -n 1 nvidia-smi

   # Terminal 2: Run inference
   ollama run llama3.2:3b "Explain GPU acceleration in one paragraph"

   # Expected behavior (if custom build worked):
   # - GPU utilization spikes to 60-90% ‚úÖ
   # - VRAM increases by ~2-2.5GB ‚úÖ
   # - Inference speed: ~30-60 tokens/sec (GTX 960) ‚úÖ
   # - CPU usage stays low (<20%) ‚úÖ

   # If GPU stays at 0%:
   # - Custom build failed to include compute 5.2
   # - Check journalctl -u ollama for "no kernel image" error
   # - Rebuild overlay with correct cmakeFlags
   ```
7. ‚úÖ **Test 7B model (optional, very tight on VRAM)**
   ```bash
   # Close other GPU apps first!
   ollama pull llama3.2:7b-q4_0  # Quantized version

   # Monitor VRAM carefully
   nvidia-smi
   # Available: ~2.4GB after desktop (4096 - 1686)
   # 7B q4_0 needs: ~3.5GB
   # Total: ~5.1GB required
   # Result: Will likely OOM unless desktop is minimal

   # Recommendation: Stick with 3B models for GTX 960
   ```

**Model Size Recommendations for 4GB VRAM:**
- **3B models:** ~2-3GB VRAM ‚úÖ Comfortable, recommended
- **7B quantized (q4_0):** ~3.5GB VRAM ‚ö†Ô∏è Very tight, close other apps
- **7B full precision:** ~7GB VRAM ‚ùå Will not fit
- **13B+:** ‚ùå Will not fit

**Expected Results:**
- GPU utilization during inference: 60-90%
- VRAM usage: +2-3GB (depending on model)
- Inference speed: 30-60 tokens/sec for 3B (10-15x faster than CPU)
- Inference speed: 15-30 tokens/sec for 7B quantized (if fits in VRAM)

---

**Subtask 8.2.2: Create LLM Agent Wrappers (FIXED)**

**Objective:** Provide easy CLI wrappers for GPU-accelerated LLM agents

**Original Plan Had Bugs:** Fixed in this revision

**Implementation:**

```nix
# hosts/shoshin/nixos/modules/applications/llm-agents.nix
{ config, pkgs, ... }:
{
  environment.systemPackages = with pkgs; [
    # GPU-accelerated local Claude alternative
    (writeShellScriptBin "claude-local" ''
      #!/usr/bin/env bash
      set -euo pipefail

      # Check if GPU mode requested
      USE_GPU=false
      if [[ "''${1:-}" == "--gpu" ]]; then
        USE_GPU=true
        shift  # Remove --gpu from args
      fi

      if $USE_GPU; then
        # Ensure ollama service is running
        if ! systemctl --user is-active ollama.service >/dev/null 2>&1; then
          echo "Starting ollama service..." >&2
          systemctl --user start ollama.service || {
            echo "Failed to start ollama, falling back to cloud Claude" >&2
            exec ${pkgs.claude}/bin/claude "$@"
          }
          # Wait for service to be ready
          sleep 2
        fi

        # Check VRAM availability before loading model
        VRAM_FREE=$(nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits)
        if [ "$VRAM_FREE" -lt 2000 ]; then
          echo "Warning: Low VRAM (''${VRAM_FREE}MB free). Close GPU apps for better performance." >&2
        fi

        # Try GPU inference, fall back to Claude on failure
        if ! ${pkgs.ollama}/bin/ollama run llama3.2:3b "$@"; then
          echo "GPU inference failed, falling back to cloud Claude" >&2
          exec ${pkgs.claude}/bin/claude "$@"
        fi
      else
        # Use cloud Claude directly
        exec ${pkgs.claude}/bin/claude "$@"
      fi
    '')

    # LLM server status check
    (writeShellScriptBin "llm-status" ''
      #!/usr/bin/env bash

      echo "=== Local LLM Status ==="
      echo ""

      # Service status
      echo "Ollama Service:"
      systemctl --user status ollama.service | grep "Active:"
      echo ""

      # GPU info
      echo "GPU:"
      nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader
      echo ""

      # Available models
      echo "Available Models:"
      ${pkgs.ollama}/bin/ollama list || echo "Ollama not running"
      echo ""

      # Quick recommendations
      VRAM_FREE=$(nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits || echo "0")
      echo "VRAM Status: ''${VRAM_FREE}MB free"
      if [ "$VRAM_FREE" -gt 2500 ]; then
        echo "‚úÖ Can load 3B or 7B model"
      elif [ "$VRAM_FREE" -gt 1500 ]; then
        echo "‚ö†Ô∏è  Can load 3B model only"
      else
        echo "‚ùå Low VRAM - close GPU apps before loading model"
      fi
    '')

    # Model management helper
    (writeShellScriptBin "llm-models" ''
      #!/usr/bin/env bash

      case "''${1:-list}" in
        list)
          echo "Installed Models:"
          ${pkgs.ollama}/bin/ollama list
          ;;
        pull)
          if [ -z "''${2:-}" ]; then
            echo "Usage: llm-models pull MODEL_NAME"
            echo "Example: llm-models pull llama3.2:3b"
            exit 1
          fi
          ${pkgs.ollama}/bin/ollama pull "$2"
          ;;
        remove)
          if [ -z "''${2:-}" ]; then
            echo "Usage: llm-models remove MODEL_NAME"
            exit 1
          fi
          ${pkgs.ollama}/bin/ollama rm "$2"
          ;;
        info)
          if [ -z "''${2:-}" ]; then
            echo "Usage: llm-models info MODEL_NAME"
            exit 1
          fi
          ${pkgs.ollama}/bin/ollama show "$2"
          ;;
        *)
          echo "Usage: llm-models {list|pull|remove|info} [MODEL_NAME]"
          echo ""
          echo "Commands:"
          echo "  list          - List installed models"
          echo "  pull MODEL    - Download a model"
          echo "  remove MODEL  - Remove a model"
          echo "  info MODEL    - Show model details"
          exit 1
          ;;
      esac
    '')
  ];

  # Shell aliases for convenience
  environment.shellAliases = {
    # GPU-first inference
    "llm" = "ollama run llama3.2:3b";
    "llm-gpu" = "claude-local --gpu";

    # Quick model switching
    "llm-3b" = "ollama run llama3.2:3b";
    "llm-7b" = "ollama run llama3.2:7b-q4_0";  # If enough VRAM
  };
}
```

**Usage Examples:**

```bash
# Check LLM system status
llm-status

# List installed models
llm-models list

# Download a new model
llm-models pull llama3.2:3b

# Use GPU-accelerated local inference
claude-local --gpu "Write a hello world program"

# Use cloud Claude (no GPU)
claude-local "Write a hello world program"

# Quick inference (alias)
llm "Explain recursion"

# Check model info
llm-models info llama3.2:3b

# Remove unused model (free VRAM)
llm-models remove llama3.2:7b-q4_0
```

**Expected Results:**
- Easy CLI interface for GPU LLM inference
- Automatic fallback to cloud if GPU unavailable
- VRAM checking before model loading
- Model management tools

---

### Task 8.1: CK Semantic Search GPU Acceleration

**Objective:** Rebuild ck with GPU-enabled ONNX Runtime

**Status:** Existing detailed plan at `docs/plans/2025-12-14-ck-rebuild-for-gpu-usage-plan.md`

**Critical Blocker (from research):**
> "FastEmbed's Rust bindings do not expose a provider toggle"

**Impact:** Even with GPU-enabled ONNX Runtime, CK may still default to CPU.

**Implementation Strategy:**

**Option A: Wait for Upstream (RECOMMENDED)**
1. Monitor FastEmbed/CK GitHub for GPU provider support
2. Skip this task for now, proceed with Firefox + Ollama optimization
3. Revisit when upstream adds provider selection
4. Estimated timeline: Unknown (upstream feature request needed)

**Option B: Fork and Patch (Advanced)**
1. Fork ck-search repository
2. Modify FastEmbed integration to expose CUDA provider
3. Create custom derivation in home-manager overlays
4. Maintain fork until upstream merges
5. Estimated time: 8-12 hours (complex)

**Recommendation:** Choose Option A unless user has strong preference for Option B.

**If proceeding with Option B:**
- Follow existing plan at `docs/plans/2025-12-14-ck-rebuild-for-gpu-usage-plan.md`
- Create `onnxruntime-gpu` overlay with CUDA 11.0
- Patch `home-manager/mcp-servers/rust-custom.nix`
- Add `programs.ck.enableGpu` option
- Test and benchmark

**Expected Results (if successful):**
- CK semantic search: CPU-only ‚Üí 60-80% GPU
- Indexing speed: 2-4x faster
- VRAM usage: +500-800MB
- **Caveat:** Uncertain due to upstream limitation

**Decision Point:**
- [ ] **Option A:** Skip CK GPU optimization for now (recommended)
- [ ] **Option B:** Proceed with fork and patch (advanced, time-consuming)

---

## Phase 8 Completion Criteria (REVISED)

**Must Verify:**
- [ ] CUDA 11.0 toolkit installed and accessible (nvcc --version)
- [ ] Ollama service running with CUDA support
- [ ] Test model (llama3.2:3b) downloaded
- [ ] GPU inference working (60-90% GPU util during inference)
- [ ] Inference speed 10-15x faster than CPU baseline
- [ ] Agent wrappers (claude-local, llm-status) working
- [ ] VRAM monitoring shows expected usage
- [ ] No system instability

**Optional (CK):**
- [ ] CK GPU enablement decision made (Option A or B)
- [ ] If Option B: CK rebuilt with GPU support

**Realistic Outcome:**
- GPU utilization during LLM: 60-90%
- VRAM usage: +2-3GB (model dependent)
- LLM inference: 10-15x faster (30-60 tokens/sec for 3B)
- Overall GPU util: 25-40% ‚Üí 50-70% (when inference active)

---

## Combined Phases 7-8: Expected Results (FINAL REVISED WITH RESEARCH)

### Phase 7 Impact (Browser & Media) - INCREASED EXPECTATIONS

‚úÖ **CORRECTED:** VP9 8-bit decode IS supported!

- **Firefox GPU:** 8MB ‚Üí 200-400MB (H.264 + VP9 8-bit video)
- **CPU reduction:** 40-55% weighted average (**increased** from 20-30%, VP9 support confirmed)
- **VRAM:** +300-500MB
- **GPU util:** 14% ‚Üí 30-45% (higher due to VP9 coverage)
- **Video coverage:** ‚úÖ **70-90% of YouTube videos use GPU decode!**

### Phase 8 Impact (AI Agents) - WITH CUSTOM BUILD

‚ö†Ô∏è **Requires custom Ollama build** with compute capability 5.2

- **LLM GPU:** 0% ‚Üí 60-90% (when active)
- **VRAM:** +2-3GB (model in memory)
- **Inference speed:** 10-15x faster (30-60 tokens/sec for 3B)
- **GPU util:** 30-45% ‚Üí 50-70% (when LLM active)
- **Build time:** +30 minutes (first-time custom build)

### Combined Total (CORRECTED)

- **GPU utilization:** 14% ‚Üí 50-70% ‚úÖ (achievable with VP9 + H.264 + LLM)
- **VRAM utilization:** 41% ‚Üí 65-75% ‚úÖ
- **CPU offloading:** **40-55% for media** (corrected from 20-30%), 90-95% for LLM
- **Power efficiency:** Better performance/watt on supported workloads
- **Faster workflows:** 10-15x LLM inference, **70-90% video decode coverage**

### Realistic Expectations (CORRECTED)

‚úÖ **GOOD NEWS:**
- **Most YouTube videos WILL benefit** (H.264 + VP9 8-bit = 70-90% coverage)
- VP9 8-bit hardware decode confirmed (official NVIDIA matrix)
- Performance expectations INCREASED from original pessimistic estimates

‚ö†Ô∏è **LIMITATIONS:**
- VP9 10-bit and AV1 still CPU fallback (10-30% of content)
- HEVC decode NOT supported (encode only)
- 7B models very tight on 4GB VRAM
- CK GPU acceleration uncertain (upstream blocker)
- Cannot run all GPU apps simultaneously (VRAM limit)
- **Custom Ollama build required** (NixPkgs limitation)

---

## Risk Assessment & Mitigation

### Risk Matrix

| Risk | Severity | Probability | Mitigation |
|------|----------|-------------|------------|
| Driver downgrade breaks Wayland | High | Medium | Test in VM, keep Option A first |
| VRAM exhaustion crashes compositor | High | Medium | VRAM monitor, priority system |
| Boot failure after NVIDIA changes | Medium | Low | TTY rollback, system backup |
| Thermal issues (14% ‚Üí 70% util) | Medium | Medium | Thermal monitoring, fan curve |
| Performance regression on VP9 | Low | Low | Codec check, fallback to CPU |

### Mitigation Implementations

**1. Thermal Monitoring & Protection:**

```nix
# Add to nvidia.nix
hardware.nvidia.powerManagement.enable = true;

systemd.services.gpu-thermal-monitor = {
  description = "GPU thermal and VRAM monitor";
  wantedBy = [ "multi-user.target" ];
  script = ''
    #!/usr/bin/env bash
    while true; do
      # Temperature check
      TEMP=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader)
      if [ $TEMP -gt 85 ]; then
        notify-send -u critical "GPU Temperature Warning" "GPU at ''${TEMP}¬∞C - reducing load"
        # Stop non-essential GPU services
        systemctl stop ollama 2>/dev/null || true
      elif [ $TEMP -gt 75 ]; then
        notify-send -u normal "GPU Temperature High" "GPU at ''${TEMP}¬∞C"
      fi

      # VRAM check (from Phase 0 resource plan)
      USED=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
      TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
      PERCENT=$((USED * 100 / TOTAL))

      if [ $PERCENT -gt 95 ]; then
        notify-send -u critical "GPU Memory Critical" "''${PERCENT}% VRAM used - stopping background services"
        systemctl stop ollama 2>/dev/null || true
      fi

      sleep 30
    done
  '';
};
```

**2. System Backup & Rollback:**

```bash
# Before Phase 7 implementation
sudo nixos-rebuild build
# Creates backup generation

# If something breaks after rebuild:
# Option 1: Rollback via bootloader (reboot, select previous generation)
# Option 2: Rollback from TTY (Ctrl+Alt+F2)
sudo nixos-rebuild switch --rollback

# Option 3: Rollback specific generation
nixos-rebuild list-generations
sudo nixos-rebuild switch --rollback --generation 123
```

**3. Emergency Recovery Procedure:**

```markdown
## If System Won't Boot After GPU Changes

1. **Access TTY:** Press Ctrl+Alt+F2 at boot
2. **Login** with your user credentials
3. **Rollback:**
   ```bash
   sudo nixos-rebuild switch --rollback
   ```
4. **Reboot:**
   ```bash
   sudo reboot
   ```

## If Wayland Broken (Black Screen, Compositor Crash)

1. **Switch to X11 temporarily:**
   - Edit: `hosts/shoshin/nixos/modules/workspace/plasma.nix`
   - Change: `sddm.wayland.enable = false;`
   - Rebuild: `sudo nixos-rebuild switch`

2. **Test GPU config under X11**
3. **Debug Wayland issues**
4. **Re-enable Wayland when fixed**
```

---

## Comprehensive Testing Plan

### Pre-Implementation: Baseline Capture

(Already covered in Phase 0.1.1)

- [ ] GPU metrics captured
- [ ] Firefox about:support saved
- [ ] CPU usage during video measured
- [ ] Package availability verified

### Phase 7 Testing

**Functional Tests:**
- [ ] Firefox plays H.264 video with GPU (check nvidia-smi)
- [ ] Firefox shows "Hardware H264: Supported" in about:support
- [ ] Firefox correctly falls back to CPU for VP9 (no crashes)
- [ ] Brave GPU acceleration working
- [ ] mpv using NVDEC for local video

**Regression Tests:**
- [ ] Existing apps still work (Steam, VLC, screen recording)
- [ ] Multi-monitor setup unaffected
- [ ] KWin compositor stable
- [ ] No performance degradation on CPU tasks

**Load Tests:**
- [ ] Firefox (2 tabs video) + Brave (1 tab video) simultaneously
- [ ] VRAM stays under 2500MB (safe threshold)
- [ ] Desktop remains responsive

### Phase 8 Testing

**Functional Tests:**
- [ ] Ollama starts and detects CUDA
- [ ] 3B model loads and runs
- [ ] GPU utilization 60-90% during inference
- [ ] Inference speed 10x+ faster than CPU baseline
- [ ] Agent wrappers (claude-local) working
- [ ] Model management (llm-models) working

**Stress Tests:**
- [ ] Continuous LLM inference for 1 hour
- [ ] GPU temperature stays < 80¬∞C
- [ ] No VRAM leaks (memory stable)
- [ ] No thermal throttling

**Fallback Tests:**
- [ ] Claude-local falls back to cloud if GPU fails
- [ ] Ollama service auto-restarts on crash
- [ ] VRAM monitor triggers at 90%+

**Integration Tests:**
- [ ] Firefox video + Ollama 3B simultaneously (VRAM conflict)
- [ ] VRAM monitor detects pressure, sends notification
- [ ] KWin doesn't crash when VRAM at 95%
- [ ] Priority system: desktop > apps (compositor always stable)

### Post-Implementation: Validation

**1-Week Stability Test:**
- [ ] System stable for 7 days continuous use
- [ ] No crashes, freezes, or GPU hangs
- [ ] Thermal levels acceptable
- [ ] No functionality loss

**Performance Benchmarks:**
```bash
# LLM inference speed (before/after)
time ollama run llama3.2:3b "Count from 1 to 100"
# Before (CPU): ~30-40 seconds
# After (GPU): ~3-5 seconds (10x speedup)

# Video CPU usage (H.264)
# Play H.264 video, measure CPU with top
# Before: 40-60% CPU
# After: 10-20% CPU (50-75% reduction)

# CK semantic search (if implemented)
time ck --sem "test query" . --jsonl
# Before: X seconds
# After: ~0.25-0.5x seconds (2-4x speedup expected)
```

---

## Implementation Timeline (REVISED)

### Week 1: Environment Audit & Phase 7

**Day 1 (2-3 hours):**
- Complete Phase 0: Baseline capture, verification
- Decision on driver strategy
- System backup if needed

**Day 2-3 (4-6 hours):**
- Implement Phase 7.1: Firefox VA-API (with Wayland config)
- Implement Phase 7.1.2: Brave optimization
- Test and validate browser GPU usage

**Day 4 (2-3 hours):**
- Implement Phase 7.2: Media player GPU
- Implement Phase 7.3: Electron apps GPU
- Test and validate

**Day 5 (Buffer):**
- Fix any issues from Phase 7
- Run stress tests
- Validate stability

### Week 2: Phase 8 (AI Agents)

**Day 8 (3-4 hours):**
- Implement Phase 8.3: CUDA 11.0 environment (FIRST!)
- Verify CUDA installation
- Test driver compatibility

**Day 9-10 (4-6 hours):**
- Implement Phase 8.2.1: Ollama setup
- Download models (3B, maybe 7B)
- Test GPU inference

**Day 11 (2-3 hours):**
- Implement Phase 8.2.2: Agent wrappers
- Test claude-local, llm-status tools
- Benchmark inference speed

**Day 12 (Optional, 4-8 hours):**
- Task 8.1: CK GPU rebuild (if choosing Option B)
- OR: Skip CK, use day for testing

**Day 13-14 (Buffer):**
- Comprehensive testing
- Stress tests
- Performance validation
- Documentation of actual results

**Total Realistic Time:** 20-30 hours over 2-3 weeks

---

## Troubleshooting

### Issue: CUDA Version Mismatch

**Symptom:** Applications fail with "CUDA version mismatch" or "unsupported compute capability"

**Diagnosis:**
```bash
# Verify compute capability
nvidia-smi --query-gpu=compute_cap --format=csv
# Should show: 5.2

# Check CUDA version
nvcc --version
# Should show: CUDA 11.x, NOT 12.x

# Check application CUDA linking
ldd $(which ollama) | grep cuda
# Should link to CUDA 11.x libraries
```

**Solution:**
- Verify CUDA 11.0 installed correctly (Phase 8.3)
- Check CUDA_PATH and CUDA_HOME environment variables
- Rebuild applications against CUDA 11.0
- If persistent: Consider driver downgrade to 470.x

---

### Issue: VA-API Not Working in Firefox

**Symptom:** Firefox still shows "Hardware H264: Unsupported"

**Diagnosis:**
```bash
# Check VA-API driver
vainfo
# Should show: NVIDIA VDPAU driver

# Check Firefox environment
ps aux | grep firefox
env | grep -E "(LIBVA|MOZ_|EGL)"
# Should show: LIBVA_DRIVER_NAME=nvidia, MOZ_ENABLE_WAYLAND=1

# Check VDPAU
vdpauinfo | head -20
# Should list supported codecs including H.264
```

**Solutions:**
1. Ensure nvidia-vaapi-driver installed (should be in nvidia.nix:20)
2. Verify Wayland environment variables set (MOZ_ENABLE_WAYLAND=1)
3. Restart Firefox completely (close all instances)
4. Clear Firefox profile and test with fresh profile
5. Check about:config for overrides that might disable hardware decode
6. Try disabling RDD sandbox: `MOZ_DISABLE_RDD_SANDBOX=1 firefox`

---

### Issue: Ollama Not Using GPU

**Symptom:** Ollama runs but GPU utilization stays at 0%

**Diagnosis:**
```bash
# Check Ollama CUDA support
ollama --version
journalctl -u ollama -n 100 | grep -i cuda
# Should show: CUDA available/enabled

# Check CUDA libraries
ldd $(which ollama) | grep cuda
# Should show CUDA 11.x libs

# Verify GPU accessible
nvidia-smi
# GPU should be visible

# Check environment
systemctl show ollama | grep Environment
# Should include CUDA_VISIBLE_DEVICES=0
```

**Solutions:**
1. Verify CUDA 11.0 toolkit installed (Phase 8.3 complete)
2. Check Ollama built with CUDA support (cudaPackages override)
3. Restart ollama service: `systemctl restart ollama`
4. Set CUDA_VISIBLE_DEVICES: `export CUDA_VISIBLE_DEVICES=0`
5. Check GPU memory not exhausted (free VRAM needed)
6. Verify compute capability recognized: `nvidia-smi --query-gpu=compute_cap`
7. If all fails: Rebuild Ollama with explicit CUDA 11.0 flags

---

### Issue: Out of VRAM (OOM)

**Symptom:** Applications crash with "out of memory" error, compositor hangs

**Immediate Response:**
```bash
# Check VRAM usage
nvidia-smi

# Kill non-essential GPU processes
killall ollama
systemctl stop ollama

# If compositor frozen:
# Ctrl+Alt+F2 (TTY)
# systemctl restart sddm
```

**Prevention:**
1. Use 3B models instead of 7B
2. Close GPU apps before loading LLM
3. Monitor VRAM with `llm-status`
4. Enable VRAM monitoring service (see Risk Mitigation)
5. Follow priority system (desktop > interactive > LLM > background)

**Resource Limits:**
```markdown
Safe Scenarios (won't OOM):
- Desktop + Firefox video + Kitty: ~2GB ‚úÖ
- Desktop + Ollama 3B: ~3.5GB ‚úÖ
- Desktop + Ollama 3B + minimal apps: ~3.8GB ‚úÖ

Unsafe Scenarios (will OOM):
- Desktop + Ollama 7B + anything else: >4GB ‚ùå
- Desktop + Ollama 3B + Firefox video + CK: >4.5GB ‚ùå

Rule: Only ONE memory-intensive GPU task at a time (Ollama OR CK OR games)
```

---

### Issue: High GPU Temperature

**Symptom:** GPU temperature >80¬∞C, thermal throttling

**Diagnosis:**
```bash
# Monitor temperature
watch -n 1 'nvidia-smi --query-gpu=temperature.gpu,power.draw,utilization.gpu --format=csv'

# Check fan speed
nvidia-smi --query-gpu=fan.speed --format=csv

# Check if throttling
nvidia-smi --query-gpu=clocks_throttle_reasons.active --format=csv
```

**Solutions:**
1. Clean GPU heatsink and fans (dust buildup)
2. Improve case airflow
3. Set custom fan curve:
   ```bash
   nvidia-settings -a "[gpu:0]/GPUFanControlState=1"
   nvidia-settings -a "[fan:0]/GPUTargetFanSpeed=70"
   ```
4. Reduce GPU workload intensity
5. Enable thermal monitor service (see Risk Mitigation)
6. Consider undervolting GPU (advanced)

**Safe Temperature Ranges:**
- Idle: 30-45¬∞C ‚úÖ
- Light load: 45-65¬∞C ‚úÖ
- Heavy load: 65-80¬∞C ‚ö†Ô∏è Acceptable
- Critical: >85¬∞C ‚ùå Reduce load or improve cooling

---

## Documentation & References

### Local Documentation
- **This Plan (Updated):** `docs/plans/nixos-shoshin-gpu-optimization-plan-UPDATED.md`
- **Original Plan:** `docs/plans/nixos-shoshin-gpu-optimization-plan.md`
- **CK GPU Research:** `docs/researches/2025-12-14_ck_gpu_investigation.md`
- **CK GPU Plan:** `docs/plans/2025-12-14-ck-rebuild-for-gpu-usage-plan.md`
- **Memory Optimization:** `docs/researches/nixos-shoshin-system-memory-optimization.md`
- **CPU Optimization:** `docs/researches/nixos-shoshin-cpu-skylake-tuning.md`

### External References

**VA-API for NVIDIA:**
- https://github.com/elFarto/nvidia-vaapi-driver
- https://wiki.archlinux.org/title/Hardware_video_acceleration
- https://ossmalta.eu/get-firefox-va-api-hardware-acceleration-working-on-nvidia-gpu/

**LLM Inference:**
- llama.cpp: https://github.com/ggerganov/llama.cpp
- Ollama: https://ollama.ai/
- vLLM: https://github.com/vllm-project/vllm (not compatible with GTX 960)

**CUDA & NixOS:**
- NixOS CUDA wiki: https://wiki.nixos.org/wiki/CUDA
- NVIDIA CUDA support matrix: https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/
- Maxwell GPU support: https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)
- GTX 960 specs: https://www.techpowerup.com/gpu-specs/geforce-gtx-960.c2620

**ONNX Runtime:**
- CUDA EP requirements: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html

---

## Completion Checklist (FINAL)

### Phase 0: Environment Audit
- [ ] Baseline metrics captured
- [ ] Current config reviewed
- [ ] Package availability verified
- [ ] Driver strategy decided
- [ ] VRAM resource plan understood
- [ ] System backup created (if needed)

### Phase 7: Browser & Media
- [ ] Firefox VA-API enabled (with Wayland config)
- [ ] Firefox shows Hardware H264 supported
- [ ] Codec limitations understood (VP9/AV1 won't accelerate)
- [ ] Brave GPU optimization applied
- [ ] mpv using NVDEC
- [ ] Electron apps (VSCode, Obsidian) optimized
- [ ] Desktop stable, no compositor crashes
- [ ] CPU usage reduced for H.264 content

### Phase 8: AI Agents
- [ ] CUDA 11.0 toolkit installed FIRST
- [ ] CUDA environment verified (nvcc --version)
- [ ] Ollama service running with CUDA support
- [ ] Test model (llama3.2:3b) working
- [ ] GPU inference 10x+ faster than CPU
- [ ] Agent wrappers functional
- [ ] VRAM monitoring active
- [ ] Thermal monitoring active
- [ ] CK decision made (skip or implement)

### Overall Success
- [ ] GPU utilization: 14% ‚Üí 50-70%
- [ ] VRAM utilization: 41% ‚Üí 65-75%
- [ ] CPU reduction: 20-30% media, 90%+ LLM
- [ ] No functionality loss
- [ ] System stable for 1 week
- [ ] Performance validated with benchmarks
- [ ] Documentation updated with actual results

---

**Plan Status:** Phase 0 COMPLETE - Prerequisites Assessment Required
**Phase 0 Completion:** 2025-12-15 ‚úÖ
**Prerequisites Status:** ‚ö†Ô∏è BLOCKERS IDENTIFIED - See prerequisites status document
**Critical Blocker:** zram at 100% capacity (3.9GB full) - Must increase to 75-100% before Phase 7
**Next Step:** Apply zram fix (hosts/shoshin/nixos/modules/system/zram.nix), then begin Phase 7
**Estimated Total Time:** 20-30 hours over 2-3 weeks (after prerequisites resolved)
**Review Date:** After Phase 7 and Phase 8 completion
**Success Criteria:** Realistic expectations met, system stable, no regressions

**Documentation:**
- Research Findings: `docs/researches/2025-12-14-gpu-plan-technical-research-findings.md`
- Prerequisites Status: `docs/researches/2025-12-15-gpu-optimization-prerequisites-status.md`
- Baseline Metrics: `sessions/gpu-optimization-baseline/`
- Session Summary: `sessions/summaries/12-15-2025_SUMMARY_GPU_OPTIMIZATION_PLAN_RESEARCH_AND_PREREQUISITES.md`

---

**Revision Notes:**
- Added comprehensive Phase 0 for prerequisite verification
- Fixed nvidia-vaapi-driver assumption (already installed)
- Lowered performance expectations based on codec reality
- Reordered Phase 8 (CUDA before Ollama)
- Doubled time estimates to realistic values
- Added Wayland configuration
- Added Electron apps optimization
- Enhanced testing, risk mitigation, and troubleshooting
- Addressed all 20 issues found in ultrathink review

**End of Updated GPU Optimization Plan**

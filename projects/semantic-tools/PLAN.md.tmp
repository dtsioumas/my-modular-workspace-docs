# Semantic Search Tools Integration Plan

**Author:** mitsio + Claude Code
**Date:** 2025-12-01
**Status:** Ready for Implementation
**ADRs:** ADR-005, ADR-007
**Priority:** High (enables Claude Code semantic search)

---

## Executive Summary

This plan integrates local semantic search tools into my-modular-workspace to enable:
1. **Code search by meaning** (not just keywords)
2. **Claude Code MCP integration** for AI-assisted search
3. **grep replacement** with semantic capabilities

**Tools Selected:**
- **ck (ck-search)** - PRIMARY: MCP server, 100% local, grep-compatible
- **w2vgrep** - SECONDARY: Word2Vec semantic grep (already partially integrated)

**Tools Skipped:**
- **semtools** - Optional, add later if document parsing needed
- **Open Semantic Search** - Too heavy for personal workspace

---

## Phase 1: ck (ck-search) Integration

**Priority:** High
**Estimated Effort:** 2-3 hours
**Dependencies:** None

### Step 1.1: Create home-manager/ck-search.nix

```nix
# home-manager/ck-search.nix
{ config, pkgs, lib, ... }:

{
  # ====================================
  # ck-search - Semantic Code Search
  # ====================================
  # Local semantic and hybrid BM25 grep/search tool
  # Repo: https://github.com/BeaconBay/ck
  # Binary: ck

  home.packages = with pkgs; [
    (rustPlatform.buildRustPackage rec {
      pname = "ck-search";
      version = "0.7.0";

      src = fetchFromGitHub {
        owner = "BeaconBay";
        repo = "ck";
        rev = version;
        # TODO: Get hash with: nix-prefetch-github BeaconBay ck --rev 0.7.0
        sha256 = lib.fakeHash;
      };

      cargoLock = {
        lockFile = "${src}/Cargo.lock";
        allowBuiltinFetchGit = true;
      };

      # Optimize build
      CARGO_PROFILE_RELEASE_LTO = "thin";

      # Native dependencies (if needed)
      nativeBuildInputs = [ pkg-config ];
      buildInputs = lib.optionals stdenv.isDarwin [ darwin.apple_sdk.frameworks.Security ];

      meta = {
        description = "Semantic and hybrid BM25 grep/search tool for AI and humans";
        homepage = "https://github.com/BeaconBay/ck";
        license = with lib.licenses; [ mit asl20 ];
        mainProgram = "ck";
        platforms = lib.platforms.unix;
      };
    })
  ];

  # Note: ck config is per-project (.ckignore), not user-level
  # MCP server registration handled separately in Claude Code settings
}
```

### Step 1.2: Get Correct Hashes

```bash
# Get source hash
nix-prefetch-github BeaconBay ck --rev 0.7.0

# Update sha256 in ck-search.nix with result

# Build once to get cargoHash (if cargoLock fails)
# The error will show the correct hash
nix build -L
```

### Step 1.3: Add Import to home.nix

```nix
# In home-manager/home.nix, add:
imports = [
  # ... existing imports ...
  ./ck-search.nix        # Semantic code search with MCP
];
```

### Step 1.4: Build and Test

```bash
# Switch home-manager
home-manager switch --flake .#mitsio@shoshin

# Test binary
ck --version
ck --help

# Test semantic search
ck --sem "rclone sync" ~/.MyHome/MySpaces/my-modular-workspace/
ck --hybrid "ansible playbook" ~/.MyHome/MySpaces/my-modular-workspace/ansible/

# Test TUI
ck --tui
```

### Step 1.5: Register MCP Server

**Option A: Via Claude Code CLI (Recommended)**
```bash
claude mcp add ck-search -s user -- ck --serve
claude mcp list  # Verify
```

**Option B: Manual Configuration**
```json
// ~/.claude/settings.json
{
  "mcpServers": {
    "ck-search": {
      "command": "ck",
      "args": ["--serve"],
      "cwd": "/home/mitsio/.MyHome/MySpaces/my-modular-workspace"
    }
  }
}
```

### Step 1.6: Verify MCP Integration

```bash
# In Claude Code, test:
# - /mcp should list ck-search
# - Semantic search should work in prompts
```

---

## Phase 2: Fix w2vgrep (semantic-grep.nix)

**Priority:** Medium
**Estimated Effort:** 1 hour
**Dependencies:** None

### Step 2.1: Fix vendorHash

```nix
# In home-manager/semantic-grep.nix, replace:
vendorHash = lib.fakeHash;

# With actual hash (get from build error):
vendorHash = "sha256-ACTUAL_HASH_HERE";
```

### Step 2.2: Build and Test

```bash
# Build
nix build -L

# Get hash from error, update, rebuild

# Test
w2vgrep --help
echo "The system configuration is working" | w2vgrep -n "config"
```

### Step 2.3: Uncomment Import

```nix
# In home-manager/home.nix, uncomment:
./semantic-grep.nix  # w2vgrep - TEMPORARILY DISABLED ‚Üí ENABLED
```

### Step 2.4: Switch and Verify

```bash
home-manager switch --flake .#mitsio@shoshin

# Verify model download
ls -lh ~/.config/semantic-grep/models/

# Test search
w2vgrep -C 2 --threshold=0.6 "configuration" docs/
```

---

## Phase 3: Navi Cheatsheet

**Priority:** Medium
**Estimated Effort:** 30 minutes

### Create local-semantic-search.cheat

```bash
# File: dotfiles/dot_local/share/navi/cheats/local-semantic-search.cheat
```

```cheat
% ck, semantic, search, code

# Semantic search for concept in codebase
ck --sem "<query>" <path>

# Hybrid search (semantic + keyword BM25)
ck --hybrid "<query>" <path>

# Interactive TUI mode
ck --tui

# Start MCP server for Claude Code
ck --serve

# grep-compatible search with context
ck -n -A 3 -B 1 "<pattern>" <path>

# Full function/class extraction with semantic search
ck --sem --full-section "<query>" <path>

# JSONL output for automation/scripting
ck --jsonl --sem "<query>" <path>

# Show relevance scores
ck --hybrid --scores "<query>" <path>

# High-confidence results only
ck --jsonl --topk 5 --threshold 0.7 "<query>" <path>

# Check index status
ck --status <path>

# Force reindex with specific model
ck --clean <path> && ck --index --model nomic-v1.5 <path>

% w2vgrep, semantic, word2vec

# Semantic word search (word2vec)
w2vgrep -C 2 -n --threshold=<threshold:0.6> "<query>" <file>

# Case-insensitive semantic search
w2vgrep -i --threshold=0.7 "<query>" <file>

# Only show matching words with scores
w2vgrep -o --threshold=0.7 "<query>" <file>

# Search with multiple patterns from file
w2vgrep -f patterns.txt -n --threshold=0.6 <file>
```

### Add to Chezmoi

```bash
chezmoi add ~/.local/share/navi/cheats/local-semantic-search.cheat
```

---

## Phase 4: Documentation Updates

**Priority:** Low
**Estimated Effort:** 30 minutes

### 4.1 Update docs/tools/README.md

Add links to new tool documentation:
- ck-search.md
- semtools.md (reference only)
- open-semantic-search.md (reference only)

### 4.2 Update CLAUDE.md (if needed)

Document MCP server availability for semantic search.

---

## Verification Checklist

### Phase 1 Complete

- [ ] `ck --version` returns version
- [ ] `ck --sem "test" .` returns results
- [ ] `ck --tui` launches interface
- [ ] `claude mcp list` shows ck-search
- [ ] Semantic search works in Claude Code

### Phase 2 Complete

- [ ] `w2vgrep --help` works
- [ ] Model file exists in ~/.config/semantic-grep/models/
- [ ] `w2vgrep "config" docs/` returns results

### Phase 3 Complete

- [ ] `navi` shows local-semantic-search category
- [ ] ck commands work from navi

---

## Rollback Plan

### If ck fails to build:

```bash
# Remove import from home.nix
# Or use cargo install as fallback:
cargo install ck-search

# Add to PATH via shell.nix
```

### If w2vgrep fails:

```bash
# Keep import commented out in home.nix
# Document manual installation option
```

---

## Success Criteria

1. **ck works as grep replacement** with semantic capabilities
2. **MCP server enables Claude Code** to search code by meaning
3. **w2vgrep provides alternative** for word-level semantic search
4. **Navi cheatsheet documents** all common commands
5. **Documentation complete** for future reference

---

## Future Enhancements (Optional)

1. **Add semtools** if document parsing becomes needed
2. **Create workspace presets** for common search paths
3. **Integrate with atuin** for command history search
4. **Add kitty integration** for search results preview

---

## Timeline

| Phase | Task | Effort | Status |
|-------|------|--------|--------|
| 1 | ck integration | 2-3h | Pending |
| 2 | w2vgrep fix | 1h | Pending |
| 3 | Navi cheatsheet | 30m | Pending |
| 4 | Documentation | 30m | Done |

**Total Estimated Effort:** 4-5 hours

---

## References

- [ck Documentation](https://beaconbay.github.io/ck/)
- [ck GitHub](https://github.com/BeaconBay/ck)
- [semantic-grep GitHub](https://github.com/arunsupe/semantic-grep)
- [docs/tools/ck-search.md](../tools/ck-search.md)
- [docs/integrations/local-semantic-search-tools/](../integrations/local-semantic-search-tools/)

---

**Next Action:** Start Phase 1, Step 1.1 - Create ck-search.nix
# Plan: Rebuilding ck-search for GPU Acceleration (Updated 2025-12-14)

## Current Context
- **CK Binary Source**: `home-manager/mcp-servers/rust-custom.nix` builds ck-search 0.7.0 with CPU-only FastEmbed + `pkgs.onnxruntime`.
- **MCP Wrapper**: `mkMcpWrapper` scripts run `ck --serve` via `systemd-run`; no GPU flags exist.
- **FastEmbed Limitations**: GPU use requires a CUDA-enabled ONNX Runtime build; the Rust crate currently links the CPU runtime and exposes no provider flag. ÓàÄciteÓàÇturn1search1ÓàÅ
- **ONNX Runtime Requirements**: CUDA Execution Provider needs matching CUDA/cuDNN versions (CUDA 12.x + cuDNN 9.x for ORT ‚â•1.19). ÓàÄciteÓàÇturn0search0ÓàÅ

## Goals
1. Produce a reproducible GPU-enabled ck derivation (ideally optional via Home-Manager module option).
2. Keep CPU build as fallback while experimenting.
3. Document exact CUDA/cuDNN expectations and verification steps.

## Work Items
1. **Research Upstream Support**
   - Track ck/FastEmbed issues requesting CUDA provider selection.
   - Determine whether `fastembed` exposes feature flags or environment overrides for GPU.
   - References: add findings to `docs/researches/2025-12-14_ck_gpu_investigation.md`.

2. **Package Dependencies**
   - Create a `pkgs.onnxruntime-gpu` overlay targeting the last CUDA/cuDNN combo supported by GTX 960 (CUDA 11.0 + cuDNN 8.x/9.x per NVIDIA‚Äôs compatibility notes). Prototype file: `home-manager/overlays/onnxruntime-gpu-11.nix`.
   - Ensure `LD_LIBRARY_PATH`/`LIBRARY_PATH` include CUDA + cuDNN.
   - Document overlay path: `home-manager/overlays/onnxruntime-gpu.nix` (to be created).

3. **Adjust ck Build**
   - Update `home-manager/mcp-servers/rust-custom.nix` to:
     - Pull in the GPU onnxruntime derivation.
     - Export `ORT_STRATEGY`, `ORT_LIB_LOCATION`, `ORT_CUDA_*` env vars.
     - Optionally include `cudatoolkit`, `cudnn`, `zlib` in `buildInputs`.
   - Consider adding a Home-Manager option `programs.ck.enableGpu = true`.

4. **Runtime Wiring**
   - Extend MCP wrapper to set CUDA-specific env vars when GPU mode is on.
   - Provide detection fallback to CPU mode if CUDA libs missing.

5. **Testing & Verification**
   - Build locally via `home-manager switch`.
   - Run `GPU=1 ck --sem "test" . --jsonl` and monitor `nvidia-smi` for load (run from host shell, capture output in docs).
   - Update docs with benchmark before/after CPU usage.

6. **Documentation & Hand-off**
   - Keep instructions updated in this plan + research doc.
   - Record any upstream patches or PR URLs referencing GPU support.

## Additional Tasks Discovered (2025-12-14)
1. **Gather Hardware/Driver Data**
   - Record current NVIDIA driver, CUDA toolkit, and cuDNN versions (`nvidia-smi`, `nvcc --version`, `ls /run/opengl-driver/lib`). (Latest snapshot: driver 570.195.03 / CUDA 12.8; no `nvcc` installed.)
   - Note whether CUDA is installed via `nixpkgs.cudatoolkit` or host system and confirm compute capability (GTX 960 = 5.2 limited to CUDA ‚â§11.0). ÓàÄciteÓàÇturn1search0ÓàÅ
2. **Overlay Wiring**
   - Decide how overlays are imported (`home-manager/flake.nix`); document required edits before creating `onnxruntime-gpu.nix`.
3. **FastEmbed Provider Check**
   - Inspect ck/FastEmbed source to confirm whether provider selection is configurable (look at `fastembed/src/lib.rs` in the ck vendored version).
4. **MCP Impact**
   - Verify the MCP wrapper still enforces resource limits when GPU mode is enabled; update `mkMcpWrapper` log messages accordingly.
5. **Testing Matrix**
   - Define explicit tests: CLI semantic search, MCP `semantic_search` tool, large-project indexing, and CPU fallback verification.
   - Track known ORT/CUDA bugs (e.g., CUDA 12.4 detection failures) and keep downgrade plan ready. ÓàÄciteÓàÇturn0search6ÓàÅ
6. **Upstream Issue Drafting**
   - Outline the GitHub issue/PR for ck requesting GPU provider support; keep notes in `docs/researches/2025-12-14_ck_gpu_investigation.md`.

## Required Context & Paths
- Docs: `docs/researches/2025-12-14_ck_gpu_investigation.md`, `docs/context/MCP_CODEX_CONFIG.md`, `docs/plans/ck-rebuild-for-gpu-usage-plan.md`
- Prompt: `sessions/prompts/ck_gpu_followup_prompt.txt`
- Home-Manager sources: `home-manager/mcp-servers/rust-custom.nix`, `home-manager/overlays/` (and overlay imports in `home-manager/flake.nix`)
- Dotfiles: `dotfiles/private_dot_codex/config.toml.tmpl`, `dotfiles/dot_bashrc.d/20-systemd-session-env.sh`
- MCP docs: ADR-010 (`docs/adrs/ADR-010-UNIFIED_MCP_SERVER_ARCHITECTURE.md`)

## External References
- ONNX Runtime CUDA EP requirements: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html
- ONNX Runtime build guide for EPs: https://onnxruntime.ai/docs/build/eps.html
- CK GitHub repo (author guide): https://github.com/BeaconBay/ck

## Session Status (2025-12-15)

### ‚úÖ Completed
1. ‚úÖ Session initialization and instruction indexing
2. ‚úÖ Hardware/driver analysis (GTX 960, driver 570.195.03)
3. ‚úÖ Research doc updated with findings
4. ‚úÖ Overlay created (`onnxruntime-gpu-11.nix` - blocked, `onnxruntime-gpu-12.nix` - active)
5. ‚úÖ Flake.nix updated with overlay import
6. ‚úÖ `programs.ck.enableGpu` option added to rust-custom.nix
7. ‚úÖ MCP wrapper updated with GPU status indicator
8. ‚úÖ Documentation created (`docs/tools/ck-gpu-support.md`)
9. ‚úÖ Changes committed to git (without bot signature)

### ‚è≥ In Progress
1. ‚è≥ **NEXT**: Rebuild home-manager with CUDA 12 overlay
2. ‚è≥ Test GPU acceleration with nvidia-smi monitoring
3. ‚è≥ Verify GPU utilization during semantic search
4. ‚è≥ Document test results (success/failure/degraded)

### üìä Current State
- **Overlay**: `overlays/onnxruntime-gpu-12.nix` (CUDA 12.8, experimental)
- **Status**: Staged in git, ready for rebuild
- **Risk**: Medium - GTX 960 officially unsupported in CUDA 12+
- **Fallback**: Easy - comment out overlay, revert to CPU

## Next Session Instructions

### 1. Rebuild and Test (IMMEDIATE)
```bash
cd ~/.MyHome/MySpaces/my-modular-workspace/home-manager
home-manager switch --flake .#mitsio@shoshin -b backup
```

### 2. Monitor GPU During Test
**Terminal 1:**
```bash
watch -n 0.5 nvidia-smi
```

**Terminal 2:**
```bash
cd ~/.MyHome/MySpaces/my-modular-workspace
ck --sem "kubernetes nvidia GPU CUDA" docs/ --n 20
```

### 3. Document Results
Record in `sessions/ck-gpu-rebuild-2025-12-14/test-results.md`:
- Build outcome (success/failure)
- GPU utilization observed (%)
- Memory usage increase (MB)
- Performance subjective assessment
- Any errors or warnings

### 4. Decision Path
**If successful:**
- Update docs with CUDA 12 confirmation
- Add to `docs/tools/ck-gpu-support.md`
- Close plan as "completed - CUDA 12 works"

**If degraded (works but slow):**
- Document performance impact
- Consider CPU-only recommendation
- Keep as optional feature

**If failed:**
- Revert overlay (comment out in flake.nix)
- Document failure mode
- Update plan to recommend CPU-only or GPU upgrade

## Files to Read After Compaction
1. **`sessions/ck-gpu-rebuild-2025-12-14/POST_COMPACTION_INSTRUCTIONS.md`** ‚≠ê START HERE
2. **`sessions/ck-gpu-rebuild-2025-12-14/cuda-12-update.md`** - Critical blocker info
3. **`sessions/ck-gpu-rebuild-2025-12-14/session-completion-summary.md`** - Full implementation
4. **`sessions/summaries/12-15-2025_SUMMARY_CK_GPU_REBUILD_SESSION.md`** - Session summary
5. This plan file

## Key Paths
- Session: `sessions/ck-gpu-rebuild-2025-12-14/`
- Summary: `sessions/summaries/12-15-2025_SUMMARY_CK_GPU_REBUILD_SESSION.md`
- Plan: `docs/plans/2025-12-14-ck-rebuild-for-gpu-usage-plan.md` (this file)
- Guide: `docs/tools/ck-gpu-support.md`
- Research: `docs/researches/2025-12-14_ck_gpu_investigation.md`
- Overlay (active): `home-manager/overlays/onnxruntime-gpu-12.nix`
- Overlay (blocked): `home-manager/overlays/onnxruntime-gpu-11.nix`
- Flake: `home-manager/flake.nix` (line 52: overlay import)
- Build: `home-manager/mcp-servers/rust-custom.nix`
